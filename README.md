# Clasificador SemÃ¡ntico de Textos ClÃ¡sicos

Sistema de Inteligencia Artificial para clasificar fragmentos de textos clÃ¡sicos en tres categorÃ­as temÃ¡ticas:
- **AretÃ©**: Excelencia y virtud moral.
- **PolÃ­tica y Poder**: Reflexiones sobre gobierno y autoridad.
- **RelaciÃ³n Dioses-Humanos**: Interacciones entre lo divino y lo mortal.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.9+**
- **MongoDB Atlas**: Base de datos NoSQL para persistencia.
- **Hugging Face Transformers**: Modelos de lenguaje avanzados.
- **BETO**: BERT pre-entrenado en espaÃ±ol para el anÃ¡lisis semÃ¡ntico.
- **Streamlit**: Interfaz de usuario moderna y accesible.
- **scikit-learn**: Herramientas de evaluaciÃ³n y mÃ©tricas.

## ğŸ“ Estructura del Proyecto

```
proyecto2/
â”œâ”€â”€ Dataset/                    # Archivos Excel con datos originales
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py              # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ db.py              # ConexiÃ³n y gestiÃ³n de MongoDB
â”‚   â”‚   â””â”€â”€ etl.py             # Pipeline de extracciÃ³n (ETL)
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ preprocessing.py   # Limpieza y balanceo de datos
â”‚   â”‚   â”œâ”€â”€ train.py           # Entrenamiento del modelo
â”‚   â”‚   â”œâ”€â”€ evaluate.py        # EvaluaciÃ³n y reportes
â”‚   â”‚   â””â”€â”€ inference.py       # MÃ³dulo para predicciones
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ streamlit_app.py   # AplicaciÃ³n web Streamlit
â”œâ”€â”€ scripts/                    # Scripts de ejecuciÃ³n paso a paso
â”‚   â”œâ”€â”€ 01_test_connection.py
â”‚   â”œâ”€â”€ 02_run_etl.py
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ models/                     # Modelos entrenados (ignorado en git)
â”œâ”€â”€ reports/                    # GrÃ¡ficos y reportes de mÃ©tricas
â””â”€â”€ run_pipeline.py             # Script maestro del pipeline
```

---

# ğŸ“– GuÃ­a de EjecuciÃ³n Paso a Paso

Esta guÃ­a te llevarÃ¡ a travÃ©s de todo el proceso, desde la configuraciÃ³n inicial hasta tener la aplicaciÃ³n funcionando.

## ğŸ“‹ Requisitos Previos

- âœ… Python 3.9+ instalado
- âœ… MongoDB Atlas cluster activo
- âœ… 8GB RAM mÃ­nimo
- âœ… Espacio en disco: ~2GB (modelos + datos)

## ğŸš€ Fase 1: ConfiguraciÃ³n Inicial

### 1. Preparar el Entorno

```powershell
# Navegar al directorio del proyecto

# Activar entorno virtual (ya creado)
.\venv\Scripts\Activate.ps1

# Verificar instalaciÃ³n de dependencias
python -c "import torch; import transformers; print('Dependencias OK')"
```

### 2. Configurar MongoDB

1. Crea un archivo `.env` en la raÃ­z del proyecto
2. Agrega tu URI de conexiÃ³n:

```
MONGO_URI=mongodb+srv://TU_USUARIO:TU_PASSWORD@TU_CLUSTER.mongodb.net/?retryWrites=true&w=majority
MONGO_DB_NAME=textos_clasicos
```

3. **Importante**: Reemplaza `TU_USUARIO`, `TU_PASSWORD` y `TU_CLUSTER` con tus credenciales reales

### 3. Verificar ConexiÃ³n

```powershell
python scripts/01_test_connection.py
```

**Resultado esperado:**
```
âœ“ ConexiÃ³n exitosa a MongoDB Atlas
âœ“ Base de datos: textos_clasicos
âœ“ Permisos de lectura/escritura: OK
âœ… TODAS LAS PRUEBAS PASARON
```

---

## ğŸ“Š Fase 2: MigraciÃ³n de Datos (ETL)

### Ejecutar ETL

```powershell
python scripts/02_run_etl.py
```

**Tiempo estimado:** 1-2 minutos

**Resultado esperado:**
- 123 documentos insertados
- DistribuciÃ³n por categorÃ­a:
  - AretÃ©: 42
  - PolÃ­tica y Poder: 38
  - Dioses-Humanos: 43

**En caso de problemas:**
```powershell
# Ejecutar con debug para ver detalles
python scripts/02_run_etl.py --debug
```

---

## ğŸ”„ Fase 3: Preprocesamiento

### Ejecutar Preprocesamiento y Balanceo

```powershell
python scripts/03_preprocess.py
```

**Tiempo estimado:** 30 segundos

**QuÃ© hace:**
1. Limpia los textos (elimina caracteres especiales, normaliza espacios)
2. Balancea las clases (undersampling por defecto)
3. Divide en train (70%), validation (15%), test (15%)
4. Guarda los conjuntos en MongoDB

**Resultado esperado:**
```
âœ“ Documentos balanceados: ~105
âœ“ Train: ~73
âœ“ Val: ~16
âœ“ Test: ~16
```

---

## ğŸ¤– Fase 4: Entrenamiento del Modelo

### Entrenar BETO

```powershell
python scripts/04_train.py
```

**â±ï¸ Tiempo estimado:**
- **CPU**: 1-3 horas
- **GPU**: 15-30 minutos

**QuÃ© hace:**
1. Carga BETO (bert-base-spanish-wwm-cased)
2. Fine-tuning con tus datos
3. Guarda el mejor modelo basado en F1-Score
4. Early stopping despuÃ©s de 2 Ã©pocas sin mejora

**Durante el entrenamiento verÃ¡s:**
```
Epoch 1/5: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] loss: 0.85 | accuracy: 0.72
Epoch 2/5: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] loss: 0.42 | accuracy: 0.88
...
```

**Resultado esperado:**
```
âœ… ENTRENAMIENTO COMPLETADO
   â€¢ F1 Macro (val): 0.82 âœ“
   â€¢ Modelo guardado en: models/clasificador_textos/final
```

### Si el F1 es < 0.80:

1. **Aumenta Ã©pocas**: Edita `src/config.py` â†’ `num_epochs: 10`
2. **Prueba oversampling**: En `preprocessing.py` cambia a `oversample`
3. **Ajusta learning rate**: Prueba `1e-5` o `3e-5`

---

## ğŸ“ˆ Fase 5: EvaluaciÃ³n

### Generar Reportes

```powershell
python scripts/05_evaluate.py
```

**Tiempo estimado:** 2-3 minutos

**QuÃ© genera:**
- `reports/confusion_matrix.png` - Matriz de confusiÃ³n visual
- `reports/metrics_by_class.png` - MÃ©tricas por categorÃ­a
- `reports/evaluation_report.json` - Reporte completo en JSON

**Resultado esperado:**
```
ğŸ“Š RESULTADOS DE EVALUACIÃ“N
   â€¢ Accuracy: 0.85
   â€¢ F1-Score (macro): 0.82
   âœ… CRITERIO CUMPLIDO: â‰¥ 0.80
```

---

## ğŸ¨ Fase 6: AplicaciÃ³n Web

### Lanzar Streamlit

```powershell
streamlit run src/app/streamlit_app.py
```

**Se abrirÃ¡ automÃ¡ticamente en:** http://localhost:8501

### Uso de la AplicaciÃ³n:

1. **Ingresa un texto** en el Ã¡rea de texto
2. **Haz clic en "Analizar Texto"**
3. **Observa**:
   - CategorÃ­a predicha
   - Nivel de confianza (%)
   - DistribuciÃ³n de probabilidades

**Ejemplo de texto para probar:**
```
"La virtud es el camino hacia la excelencia del alma."
â†’ DeberÃ­a clasificarse como "AretÃ©"
```

---

## ğŸ› SoluciÃ³n de Problemas

### Problema: Error de conexiÃ³n a MongoDB

**SoluciÃ³n:**
1. Verifica que tu cluster estÃ© activo en MongoDB Atlas
2. Revisa que el `.env` tenga la URI correcta
3. Verifica que tu IP estÃ© en la whitelist de Atlas

### Problema: "Module not found"

**SoluciÃ³n:**
```powershell
pip install -r requirements.txt --upgrade
```

### Problema: Memoria insuficiente durante entrenamiento

**SoluciÃ³n:**
1. Reduce batch_size en `src/config.py`:
   ```python
   "batch_size_cpu": 2,  # Reducir de 4 a 2
   ```
2. Considera usar Google Colab con GPU gratuita

### Problema: Emojis no se muestran en terminal

**No es un error** - Los scripts ya manejan esto automÃ¡ticamente. VerÃ¡s caracteres extraÃ±os pero el programa funciona correctamente.

---

## âœ… VerificaciÃ³n Final

Revisa que todo funcione:

```powershell
# âœ“ Datos en MongoDB
python -c "from src.data.db import get_collection; print(f'Datos: {get_collection(\"raw_texts\").count_documents({})}')"

# âœ“ Modelo entrenado existe
python -c "from pathlib import Path; print('Modelo OK' if Path('models/clasificador_textos/final').exists() else 'Sin modelo')"

# âœ“ Reportes generados
python -c "from pathlib import Path; print('Reportes OK' if Path('reports/confusion_matrix.png').exists() else 'Sin reportes')"
```

---

## ğŸ“š PrÃ³ximos Pasos

1. **Experimentar** con diferentes textos en la app
2. **Revisar** las mÃ©tricas en `reports/`
3. **Ajustar** hiperparÃ¡metros si es necesario
4. **Documentar** tus resultados
5. **Publicar** en GitHub (sin `.env` ni modelos)

---

## ğŸ” CaracterÃ­sticas del Sistema ETL

El sistema ETL implementa estrategias avanzadas para manejar la heterogeneidad de los archivos suministrados:

1.  **DetecciÃ³n Difusa de CategorÃ­as**: Maneja variaciones en los nombres de las hojas (ej: "etiqueta aretÃ©", "AretÃ©") y abreviaciones ("H. y D.").
2.  **DetecciÃ³n de MÃºltiples Formatos**: Soporta tanto hojas individuales por categorÃ­a como hojas con mÃºltiples tablas en paralelo (formato multi-columna).
3.  **BÃºsqueda Inteligente de Encabezados**: Escanea automÃ¡ticamente las filas para localizar los encabezados de las tablas (Canto, Versos, Cita), sin importar si la tabla empieza en la celda A1.

---

## ğŸš© PublicaciÃ³n en Git y Notas Importantes

### Antes de hacer commit:
1.  **Verifica `.env`**: AsegÃºrate de que tus credenciales de MongoDB NO se suban. Ya estÃ¡ en el `.gitignore`.
2.  **Modelos Pesados**: Los modelos entrenados (>500MB) estÃ¡n ignorados; cada usuario debe entrenar el suyo localmente.
3.  **Dataset**: El dataset original estÃ¡ incluido en el repositorio para facilitar la primera ejecuciÃ³n, pero considera los derechos de autor antes de hacerlo pÃºblico.

### Archivos a subir:
- CÃ³digo fuente (`src/`, `run_pipeline.py`, `scripts/`).
- `requirements.txt`, `README.md`, `.gitignore`, `.env.example`.
- Carpetas de estructura con `.gitkeep` (`models/`, `reports/`).

---

## ğŸ“ Ayuda Adicional

Si encuentras problemas:
1. Revisa esta guÃ­a
2. Ejecuta scripts con `--debug` cuando estÃ© disponible
3. Revisa los logs de error completos
4. Consulta la documentaciÃ³n de las librerÃ­as (Hugging Face, PyTorch)

Â¡Ã‰xito con tu proyecto! ğŸ‰

# Autor
Daniel Castellanos
Desarrollado como proyecto acadÃ©mico de IA.
